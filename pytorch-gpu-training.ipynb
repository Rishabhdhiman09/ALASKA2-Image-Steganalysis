{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from collections import OrderedDict, namedtuple\n",
    "from torch.optim import lr_scheduler\n",
    "from glob import glob  # find all pathnames matching certain patterns\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2  # for converting image to tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler  # return indices in sequence/random order\n",
    "import cv2\n",
    "from sklearn.metrics import *\n",
    "from tqdm.notebook import tqdm\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Seed everything for reproducable results\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\r\n",
      "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (1.18.1)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12419 sha256=dcdf49468b3eff76124df0e1042a3ce0a33918c1597b4489e26357320f978ac4\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\r\n",
      "Successfully built efficientnet-pytorch\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.6.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch\n",
    "# import efficientnet_pytorch\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Getting dataframe for iterating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 115 ms, total: 1.28 s\n",
      "Wall time: 1.56 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = []\n",
    "for label, kind in enumerate([\"Cover\", \"JMiPOD\", \"JUNIWARD\", \"UERD\"]):\n",
    "    for i, path in enumerate(glob(\"../input/alaska2-image-steganalysis/Cover/*.jpg\")):\n",
    "        if i == 2500:\n",
    "            break\n",
    "        data = {\n",
    "            \"kind\": kind,\n",
    "            \"image_name\": path.split(\"/\")[-1],\n",
    "            \"label\": label\n",
    "        }\n",
    "        dataset.append(data)\n",
    "random.shuffle(dataset)\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Changes made in fold column (0,1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group k folds\n",
    "\"\"\"\n",
    "In group K folds image name exp 0001.jpg is present in all the four image folders,\n",
    "If we take 0001.jpg in train then we will not take 0001.jpg in test (from rest of the folders)\n",
    "\"\"\"\n",
    "gkf = GroupKFold(n_splits = 5)\n",
    "\n",
    "dataset.loc[:, \"fold\"] = 0\n",
    "for fold_number, (train_index, val_index) in enumerate(gkf.split(X = dataset.index, y = dataset[\"label\"], groups = dataset[\"image_name\"])):\n",
    "    dataset.loc[dataset.iloc[val_index].index, \"fold\"] = fold_number"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train and test augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simple Augmentations\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p = 0.5),\n",
    "        A.VerticalFlip(p = 0.5),\n",
    "        A.Resize(height = 512, width = 512, p = 1.0),\n",
    "        ToTensorV2(p = 1.0),\n",
    "    ], p = 1.0)\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(height = 512, width = 512, p = 1.0),\n",
    "        ToTensorV2(p = 1.0)\n",
    "    ], p = 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT_PATH = \"../input/alaska2-image-steganalysis\"\n",
    "\n",
    "def onehot(size, target):\n",
    "    vec = torch.zeros(size, dtype = torch.float32)\n",
    "    vec[target] = 1\n",
    "    return vec\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, kinds, image_names, labels, transforms = None):\n",
    "        self.kinds = kinds\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        kind = self.kinds[index]\n",
    "        image_name = self.image_names[index]\n",
    "        label = self.labels[index]\n",
    "        image = cv2.imread(f\"{DATA_ROOT_PATH}/{kind}/{image_name}\", flags = cv2.IMREAD_COLOR)\n",
    "        # cv2.im_read --> how the image \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        if self.transforms:\n",
    "            sample = {\"image\": image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample[\"image\"]     # doubt\n",
    "            \"\"\"exp # a = {\"a\": 1, \"b\": 2}\n",
    "            # print(\"{a}\".format(**a))\"\"\"\n",
    "            \n",
    "        target = onehot(4, label)\n",
    "        return image, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.kinds.shape[0]\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return list(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def alaska_weighted_auc(labels, preds, plot = False):\n",
    "    tpr_thresholds = [0.0, 0.4, 1.0]\n",
    "    weights =        [       2,   1]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, preds, pos_label=1)\n",
    "    # data labels, preds\n",
    "    area = np.array(tpr_thresholds)[1:] - np.array(tpr_thresholds)[:-1]     # [0.4, 0.6]\n",
    "    area_normalized = np.dot(area, np.array(weights).T)  # For normalizing AUC\n",
    "    fscore = 0\n",
    "    for index, weight in enumerate(weights):\n",
    "        ymin = tpr_thresholds[index]    \n",
    "        ymax = tpr_thresholds[index + 1]\n",
    "\n",
    "        mask = (tpr > ymin) & (tpr < ymax)\n",
    "        x = np.concatenate([fpr[mask], np.linspace(fpr[mask][-1], 1, 100)])\n",
    "        y = np.concatenate([tpr[mask], [ymax] * 100])\n",
    "        y = y #(taking y as origin)\n",
    "        score = auc(x, y-ymin)\n",
    "        # Multiply score with weight\n",
    "        weighted_score = score * weight\n",
    "\n",
    "        fscore += weighted_score\n",
    "        color = [\"red\", \"green\"]\n",
    "        label = [\"x ∈ [0, 1], y ∈ [0, 0.4]\", \"x ∈ [0, 1], y ∈ [0.4, 1.0]\"]\n",
    "        \n",
    "        if plot:\n",
    "            plt.title(\"Separate plots for x ∈ [0, 1], y ∈ [0, 0.4] and x ∈ [0, 1], y ∈ [0.4, 1.0]\")\n",
    "            plt.plot(x, y, color = color[index], label = label[index])\n",
    "            plt.xlabel(\"False Positive rate\")\n",
    "            plt.ylabel(\"True Positive rate\")\n",
    "            plt.legend(loc = 2)\n",
    "#           plt.plot()\n",
    "\n",
    "        # Normalizing score\n",
    "        final_score = fscore/area_normalized\n",
    "        return final_score\n",
    "    \n",
    "class RocAucMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.y_true = np.array([0, 1])\n",
    "        self.y_pred = np.array([0.5, 0.5])\n",
    "        self.score = 0\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.argmax(axis=1).clip(min=0, max=1).astype(int)\n",
    "        y_pred = 1 - nn.functional.softmax(torch.tensor(y_pred), dim=1)[:,0]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = alaska_weighted_auc(self.y_true, self.y_pred)\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing = 0.10):\n",
    "        self.confidence = 1 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "            x = x.float()\n",
    "            target = target.float()\n",
    "            \n",
    "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
    "            nll_loss = -logprobs * target\n",
    "            nll_loss = nll_loss.sum(-1)\n",
    "    \n",
    "            smooth_loss = -logprobs.mean(dim=-1)\n",
    "\n",
    "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "            return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth\" to /root/.cache/torch/checkpoints/efficientnet-b2-8bb594d6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a408f1c6994883bc37e6214573c5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36804509.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_net():\n",
    "    net = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "    net._fc = nn.Linear(in_features=1408, out_features=4, bias=True)\n",
    "    return net\n",
    "\n",
    "mx = get_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds_data(TRAIN_BATCH_SIZE, EPOCHS, i):\n",
    "    \n",
    "    fold_number = i\n",
    "    train_dataset = DatasetRetriever(\n",
    "        kinds = dataset[dataset[\"fold\"] != fold_number].iloc[:, 0].values,\n",
    "        image_names = dataset[dataset[\"fold\"] != fold_number].iloc[:, 1].values,\n",
    "        labels = dataset[dataset[\"fold\"] != fold_number].iloc[:, 2].values,\n",
    "        transforms = get_train_transforms()\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            drop_last=True,  # take care of last batch\n",
    "            num_workers=4\n",
    "    )\n",
    "\n",
    "\n",
    "    valid_dataset = DatasetRetriever(\n",
    "        kinds=dataset[dataset['fold'] == fold_number].kind.values,\n",
    "        image_names=dataset[dataset['fold'] == fold_number].image_name.values,\n",
    "        labels=dataset[dataset['fold'] == fold_number].label.values,\n",
    "        transforms=get_valid_transforms()\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=8,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    return train_data_loader, valid_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _run():\n",
    "    \n",
    "    device = torch.device('cuda:0')\n",
    "    model = mx.to(device)\n",
    "    TRAIN_BATCH_SIZE = 8\n",
    "    EPOCHS = 2\n",
    "    \n",
    "    \n",
    "    for i in range(5):     # For five folds\n",
    "        def loss_fn(outputs, targets):\n",
    "            loss_obj = LabelSmoothing()\n",
    "            loss = loss_obj(outputs, targets)\n",
    "            return loss\n",
    "\n",
    "        def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n",
    "            model.train()\n",
    "            for bi, (X,y) in enumerate(data_loader):\n",
    "                inputs = X\n",
    "                targets = y\n",
    "\n",
    "                inputs = inputs.to(device, dtype = torch.float32)\n",
    "                targets = targets.to(device, dtype=torch.float32)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(\n",
    "                    inputs\n",
    "                )\n",
    "\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                if bi % 10 == 0:\n",
    "                    print(f'bi={bi}, loss={loss}')\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "\n",
    "        def eval_loop_fn(data_loader, model, device):\n",
    "            model.eval()\n",
    "            fin_targets = []\n",
    "            fin_outputs = []\n",
    "            for bi, (X, y) in enumerate(data_loader):\n",
    "                inputs = X\n",
    "                targets = y\n",
    "\n",
    "                inputs = inputs.to(device, dtype = torch.float32)\n",
    "                targets = targets.to(device, dtype = torch.float32)\n",
    "                outputs = model(\n",
    "                    inputs\n",
    "                )\n",
    "\n",
    "                targets_np = targets.cpu().detach().numpy()\n",
    "                outputs_np = outputs.cpu().detach().numpy()\n",
    "                fin_targets.append(targets_np)\n",
    "                fin_outputs.append(outputs_np)\n",
    "\n",
    "            return np.vstack(fin_outputs), np.vstack(fin_targets)\n",
    "        \n",
    "        \n",
    "#################################     Getting data for each fold    ######################################\n",
    "\n",
    "        train_data_loader, valid_data_loader = get_folds_data(TRAIN_BATCH_SIZE, EPOCHS, i)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"#\"*25)\n",
    "        print(f\"FOLD: {i + 1}\")\n",
    "        print(\"#\"*25)\n",
    "        \n",
    "        \n",
    "############################## Initialize lr, optimizer, scheduler for each fold separately ##################################        \n",
    "        lr = 0.001\n",
    "        num_train_steps = int(len(dataset) / TRAIN_BATCH_SIZE * EPOCHS * 0.8)\n",
    "        print(f'num_train_steps = {num_train_steps}')\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=lr)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=num_train_steps\n",
    "        )\n",
    "        \n",
    "        # Taking best model from each fold\n",
    "        best_score = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loop_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)\n",
    "            o, t = eval_loop_fn(valid_data_loader, model, device)\n",
    "    #         torch.save(model.state_dict(), \"model.bin\")\n",
    "            score = RocAucMeter()\n",
    "            score.reset()\n",
    "            score.update(t, o)\n",
    "            print(f'SCORE = {score.avg}')\n",
    "            if float(score.avg) > best_score:\n",
    "                best_score = score.avg\n",
    "                torch.save(model.state_dict(), f\"model{i}.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#########################\n",
      "FOLD: 1\n",
      "#########################\n",
      "num_train_steps = 2000\n",
      "bi=0, loss=1.4126255512237549\n",
      "bi=10, loss=1.509793996810913\n",
      "bi=20, loss=1.2633910179138184\n",
      "bi=30, loss=1.4277515411376953\n",
      "bi=40, loss=1.4665558338165283\n",
      "bi=50, loss=1.5008107423782349\n",
      "bi=60, loss=1.4777981042861938\n",
      "bi=70, loss=1.4080777168273926\n",
      "bi=80, loss=1.5895171165466309\n",
      "bi=90, loss=1.3688946962356567\n",
      "bi=100, loss=1.3446931838989258\n",
      "bi=110, loss=1.3545405864715576\n",
      "bi=120, loss=1.3193118572235107\n",
      "bi=130, loss=1.4035861492156982\n",
      "bi=140, loss=1.4206548929214478\n",
      "bi=150, loss=1.4120688438415527\n",
      "bi=160, loss=1.3810341358184814\n",
      "bi=170, loss=1.323302149772644\n",
      "bi=180, loss=1.4580987691879272\n",
      "bi=190, loss=1.3130818605422974\n",
      "bi=200, loss=1.2610474824905396\n",
      "bi=210, loss=1.4416364431381226\n",
      "bi=220, loss=1.438572883605957\n",
      "bi=230, loss=1.406258463859558\n",
      "bi=240, loss=1.4361960887908936\n",
      "bi=250, loss=1.365513563156128\n",
      "bi=260, loss=1.3752772808074951\n",
      "bi=270, loss=1.6131097078323364\n",
      "bi=280, loss=1.2928742170333862\n",
      "bi=290, loss=1.4050474166870117\n",
      "bi=300, loss=1.3412578105926514\n",
      "bi=310, loss=1.4504430294036865\n",
      "bi=320, loss=1.3632700443267822\n",
      "bi=330, loss=1.33529794216156\n",
      "bi=340, loss=1.4972585439682007\n",
      "bi=350, loss=1.4783508777618408\n",
      "bi=360, loss=1.4001243114471436\n",
      "bi=370, loss=1.3448965549468994\n",
      "bi=380, loss=1.449798345565796\n",
      "bi=390, loss=1.494500994682312\n",
      "bi=400, loss=1.419377326965332\n",
      "bi=410, loss=1.5105206966400146\n",
      "bi=420, loss=1.181410312652588\n",
      "bi=430, loss=1.3777621984481812\n",
      "bi=440, loss=1.4269323348999023\n",
      "bi=450, loss=1.2554640769958496\n",
      "bi=460, loss=1.3902266025543213\n",
      "bi=470, loss=1.4091635942459106\n",
      "bi=480, loss=1.4075672626495361\n",
      "bi=490, loss=1.377300500869751\n",
      "bi=500, loss=1.3198407888412476\n",
      "bi=510, loss=1.3866559267044067\n",
      "bi=520, loss=1.494208574295044\n",
      "bi=530, loss=1.3553270101547241\n",
      "bi=540, loss=1.3355350494384766\n",
      "bi=550, loss=1.3750709295272827\n",
      "bi=560, loss=1.4525574445724487\n",
      "bi=570, loss=1.4769470691680908\n",
      "bi=580, loss=1.3430217504501343\n",
      "bi=590, loss=1.4836493730545044\n",
      "bi=600, loss=1.3120763301849365\n",
      "bi=610, loss=1.4469187259674072\n",
      "bi=620, loss=1.4661409854888916\n",
      "bi=630, loss=1.3264496326446533\n",
      "bi=640, loss=1.4579631090164185\n",
      "bi=650, loss=1.334557056427002\n",
      "bi=660, loss=1.473191261291504\n",
      "bi=670, loss=1.308457374572754\n",
      "bi=680, loss=1.4750298261642456\n",
      "bi=690, loss=1.2945153713226318\n",
      "bi=700, loss=1.3106212615966797\n",
      "bi=710, loss=1.2932939529418945\n",
      "bi=720, loss=1.2233903408050537\n",
      "bi=730, loss=1.3243167400360107\n",
      "bi=740, loss=1.3902618885040283\n",
      "bi=750, loss=1.2313876152038574\n",
      "bi=760, loss=1.4798628091812134\n",
      "bi=770, loss=1.4443368911743164\n",
      "bi=780, loss=1.329972505569458\n",
      "bi=790, loss=1.2504462003707886\n",
      "bi=800, loss=1.273813009262085\n",
      "bi=810, loss=1.4784801006317139\n",
      "bi=820, loss=1.3307626247406006\n",
      "bi=830, loss=1.4979748725891113\n",
      "bi=840, loss=1.3966962099075317\n",
      "bi=850, loss=1.4494487047195435\n",
      "bi=860, loss=1.3046643733978271\n",
      "bi=870, loss=1.384197473526001\n",
      "bi=880, loss=1.378902554512024\n",
      "bi=890, loss=1.1866974830627441\n",
      "bi=900, loss=1.2718662023544312\n",
      "bi=910, loss=1.3550410270690918\n",
      "bi=920, loss=1.3627488613128662\n",
      "bi=930, loss=1.1920576095581055\n",
      "bi=940, loss=1.4618161916732788\n",
      "bi=950, loss=1.2928886413574219\n",
      "bi=960, loss=1.331942081451416\n",
      "bi=970, loss=1.1908189058303833\n",
      "bi=980, loss=1.2646353244781494\n",
      "bi=990, loss=1.3422412872314453\n",
      "SCORE = 0.5045950736767637\n",
      "bi=0, loss=1.2873656749725342\n",
      "bi=10, loss=1.4074764251708984\n",
      "bi=20, loss=1.1870698928833008\n",
      "bi=30, loss=1.131676435470581\n",
      "bi=40, loss=1.3691351413726807\n",
      "bi=50, loss=1.2115768194198608\n",
      "bi=60, loss=1.4217913150787354\n",
      "bi=70, loss=1.283005952835083\n",
      "bi=80, loss=1.2949256896972656\n",
      "bi=90, loss=1.0571448802947998\n",
      "bi=100, loss=1.3967463970184326\n",
      "bi=110, loss=1.3519741296768188\n",
      "bi=120, loss=1.281569004058838\n",
      "bi=130, loss=1.4236550331115723\n",
      "bi=140, loss=1.2750705480575562\n",
      "bi=150, loss=1.3006343841552734\n",
      "bi=160, loss=1.2247129678726196\n",
      "bi=170, loss=1.3504661321640015\n",
      "bi=180, loss=1.1018632650375366\n",
      "bi=190, loss=1.3088784217834473\n",
      "bi=200, loss=1.2716312408447266\n",
      "bi=210, loss=1.37075936794281\n",
      "bi=220, loss=1.2067826986312866\n",
      "bi=230, loss=1.2815148830413818\n",
      "bi=240, loss=1.4444825649261475\n",
      "bi=250, loss=1.5231339931488037\n",
      "bi=260, loss=1.2624155282974243\n",
      "bi=270, loss=1.2338318824768066\n",
      "bi=280, loss=1.568972110748291\n",
      "bi=290, loss=1.2800811529159546\n",
      "bi=300, loss=1.4295356273651123\n",
      "bi=310, loss=1.4692084789276123\n",
      "bi=320, loss=1.3728899955749512\n",
      "bi=330, loss=1.3970938920974731\n",
      "bi=340, loss=1.3432403802871704\n",
      "bi=350, loss=1.5117309093475342\n",
      "bi=360, loss=1.2353851795196533\n",
      "bi=370, loss=1.3427302837371826\n",
      "bi=380, loss=1.5115165710449219\n",
      "bi=390, loss=1.3372230529785156\n",
      "bi=400, loss=1.435477614402771\n",
      "bi=410, loss=1.399116039276123\n",
      "bi=420, loss=1.123887538909912\n",
      "bi=430, loss=1.3110864162445068\n",
      "bi=440, loss=1.3441693782806396\n",
      "bi=450, loss=1.1746971607208252\n",
      "bi=460, loss=1.2626837491989136\n",
      "bi=470, loss=1.2691967487335205\n",
      "bi=480, loss=1.2402974367141724\n",
      "bi=490, loss=1.091782569885254\n",
      "bi=500, loss=1.401505470275879\n",
      "bi=510, loss=1.4289329051971436\n",
      "bi=520, loss=1.3050639629364014\n",
      "bi=530, loss=1.3434966802597046\n",
      "bi=540, loss=1.380845546722412\n",
      "bi=550, loss=1.3706395626068115\n",
      "bi=560, loss=1.2468966245651245\n",
      "bi=570, loss=1.139784574508667\n",
      "bi=580, loss=1.0522193908691406\n",
      "bi=590, loss=1.3120548725128174\n",
      "bi=600, loss=1.2177503108978271\n",
      "bi=610, loss=1.4401662349700928\n",
      "bi=620, loss=1.215701699256897\n",
      "bi=630, loss=1.3883640766143799\n",
      "bi=640, loss=1.3450521230697632\n",
      "bi=650, loss=1.2689212560653687\n",
      "bi=660, loss=1.168533444404602\n",
      "bi=670, loss=1.3425602912902832\n",
      "bi=680, loss=1.3451898097991943\n",
      "bi=690, loss=1.186600923538208\n",
      "bi=700, loss=1.1342566013336182\n",
      "bi=710, loss=1.2154721021652222\n",
      "bi=720, loss=0.9339404106140137\n",
      "bi=730, loss=1.2879729270935059\n",
      "bi=740, loss=1.3694267272949219\n",
      "bi=750, loss=1.2257567644119263\n",
      "bi=760, loss=1.3100357055664062\n",
      "bi=770, loss=1.348140001296997\n",
      "bi=780, loss=1.2447479963302612\n",
      "bi=790, loss=1.2150777578353882\n",
      "bi=800, loss=1.096557378768921\n",
      "bi=810, loss=1.408315896987915\n",
      "bi=820, loss=1.3740453720092773\n",
      "bi=830, loss=1.3536860942840576\n",
      "bi=840, loss=1.2956371307373047\n",
      "bi=850, loss=1.450343132019043\n",
      "bi=860, loss=1.254849910736084\n",
      "bi=870, loss=1.332427740097046\n",
      "bi=880, loss=1.3094263076782227\n",
      "bi=890, loss=1.1459569931030273\n",
      "bi=900, loss=1.061977505683899\n",
      "bi=910, loss=1.1332709789276123\n",
      "bi=920, loss=1.2760422229766846\n",
      "bi=930, loss=1.3342065811157227\n",
      "bi=940, loss=1.3264236450195312\n",
      "bi=950, loss=1.2312124967575073\n",
      "bi=960, loss=1.292521357536316\n",
      "bi=970, loss=1.15114164352417\n",
      "bi=980, loss=1.2993462085723877\n",
      "bi=990, loss=1.401551604270935\n",
      "SCORE = 0.5255783284482715\n",
      "\n",
      "\n",
      "#########################\n",
      "FOLD: 2\n",
      "#########################\n",
      "num_train_steps = 2000\n",
      "bi=0, loss=1.3853166103363037\n",
      "bi=10, loss=1.3483672142028809\n",
      "bi=20, loss=1.3765652179718018\n",
      "bi=30, loss=1.3632569313049316\n",
      "bi=40, loss=1.5101532936096191\n",
      "bi=50, loss=1.3742635250091553\n",
      "bi=60, loss=1.295170545578003\n",
      "bi=70, loss=1.1330716609954834\n",
      "bi=80, loss=1.445389986038208\n",
      "bi=90, loss=1.2316417694091797\n",
      "bi=100, loss=1.5389740467071533\n",
      "bi=110, loss=1.4160505533218384\n",
      "bi=120, loss=1.3313186168670654\n",
      "bi=130, loss=1.2757525444030762\n",
      "bi=140, loss=1.382683515548706\n",
      "bi=150, loss=1.359022617340088\n",
      "bi=160, loss=1.3867347240447998\n",
      "bi=170, loss=1.2519022226333618\n",
      "bi=180, loss=1.329021692276001\n",
      "bi=190, loss=1.2828083038330078\n",
      "bi=200, loss=1.4346888065338135\n",
      "bi=210, loss=1.4581878185272217\n",
      "bi=220, loss=1.4847934246063232\n",
      "bi=230, loss=1.5206760168075562\n",
      "bi=240, loss=1.4691270589828491\n",
      "bi=250, loss=1.37965989112854\n",
      "bi=260, loss=1.513310194015503\n",
      "bi=270, loss=1.3733493089675903\n",
      "bi=280, loss=1.1148602962493896\n",
      "bi=290, loss=1.5888698101043701\n",
      "bi=300, loss=1.4594000577926636\n",
      "bi=310, loss=1.2029330730438232\n",
      "bi=320, loss=1.2160162925720215\n",
      "bi=330, loss=1.291203498840332\n",
      "bi=340, loss=1.3016936779022217\n",
      "bi=350, loss=1.531019687652588\n",
      "bi=360, loss=1.0292737483978271\n",
      "bi=370, loss=1.2839668989181519\n",
      "bi=380, loss=1.3106440305709839\n",
      "bi=390, loss=1.3677821159362793\n",
      "bi=400, loss=1.3472228050231934\n",
      "bi=410, loss=1.2349028587341309\n",
      "bi=420, loss=1.2456111907958984\n",
      "bi=430, loss=1.2849836349487305\n",
      "bi=440, loss=1.3182553052902222\n",
      "bi=450, loss=1.288132667541504\n",
      "bi=460, loss=1.369810938835144\n",
      "bi=470, loss=1.3102519512176514\n",
      "bi=480, loss=1.1429919004440308\n",
      "bi=490, loss=1.1834211349487305\n",
      "bi=500, loss=0.9699838161468506\n",
      "bi=510, loss=1.2087560892105103\n",
      "bi=520, loss=1.1698582172393799\n",
      "bi=530, loss=1.580981969833374\n",
      "bi=540, loss=1.2553982734680176\n",
      "bi=550, loss=1.2938251495361328\n",
      "bi=560, loss=1.2036898136138916\n",
      "bi=570, loss=1.092463731765747\n",
      "bi=580, loss=1.3795506954193115\n",
      "bi=590, loss=1.2187469005584717\n",
      "bi=600, loss=1.3201305866241455\n",
      "bi=610, loss=1.2633005380630493\n",
      "bi=620, loss=1.5328748226165771\n",
      "bi=630, loss=1.3228037357330322\n",
      "bi=640, loss=1.1613813638687134\n",
      "bi=650, loss=1.3321744203567505\n",
      "bi=660, loss=1.4618088006973267\n",
      "bi=670, loss=1.3427661657333374\n",
      "bi=680, loss=1.2123496532440186\n",
      "bi=690, loss=1.501927137374878\n",
      "bi=700, loss=1.4240143299102783\n",
      "bi=710, loss=1.2259892225265503\n",
      "bi=720, loss=1.59732985496521\n",
      "bi=730, loss=1.3747854232788086\n",
      "bi=740, loss=1.1815096139907837\n",
      "bi=750, loss=1.4065968990325928\n",
      "bi=760, loss=1.40098237991333\n",
      "bi=770, loss=1.0488901138305664\n",
      "bi=780, loss=1.338916301727295\n",
      "bi=790, loss=1.2061924934387207\n",
      "bi=800, loss=1.278900384902954\n",
      "bi=810, loss=1.130444049835205\n",
      "bi=820, loss=1.1591322422027588\n",
      "bi=830, loss=1.4670770168304443\n",
      "bi=840, loss=1.4171078205108643\n",
      "bi=850, loss=1.3373794555664062\n",
      "bi=860, loss=1.2888774871826172\n",
      "bi=870, loss=1.2636851072311401\n",
      "bi=880, loss=1.300058364868164\n",
      "bi=890, loss=1.190920114517212\n",
      "bi=900, loss=1.3825992345809937\n",
      "bi=910, loss=1.4331459999084473\n",
      "bi=920, loss=1.3001136779785156\n",
      "bi=930, loss=1.3443814516067505\n",
      "bi=940, loss=1.30517578125\n",
      "bi=950, loss=1.2155152559280396\n",
      "bi=960, loss=1.314967155456543\n",
      "bi=970, loss=1.349043607711792\n",
      "bi=980, loss=1.398790717124939\n",
      "bi=990, loss=1.0613230466842651\n",
      "SCORE = 0.5313900608414844\n",
      "bi=0, loss=1.310234546661377\n",
      "bi=10, loss=1.3081177473068237\n",
      "bi=20, loss=1.381565809249878\n",
      "bi=30, loss=1.2549885511398315\n",
      "bi=40, loss=1.2209794521331787\n",
      "bi=50, loss=1.495426893234253\n",
      "bi=60, loss=1.3402069807052612\n",
      "bi=70, loss=1.1284161806106567\n",
      "bi=80, loss=1.2377952337265015\n",
      "bi=90, loss=1.3090553283691406\n",
      "bi=100, loss=1.4344563484191895\n",
      "bi=110, loss=1.4132990837097168\n",
      "bi=120, loss=1.3727446794509888\n",
      "bi=130, loss=1.2835578918457031\n",
      "bi=140, loss=1.3942642211914062\n",
      "bi=150, loss=1.2041356563568115\n",
      "bi=160, loss=1.396214485168457\n",
      "bi=170, loss=1.166797399520874\n",
      "bi=180, loss=1.2980973720550537\n",
      "bi=190, loss=1.2873778343200684\n",
      "bi=200, loss=1.3782033920288086\n",
      "bi=210, loss=1.51912260055542\n",
      "bi=220, loss=1.3653206825256348\n",
      "bi=230, loss=1.2502676248550415\n",
      "bi=240, loss=1.3735649585723877\n",
      "bi=250, loss=1.176806926727295\n",
      "bi=260, loss=1.2648701667785645\n",
      "bi=270, loss=1.230820655822754\n",
      "bi=280, loss=1.1863824129104614\n",
      "bi=290, loss=1.4684960842132568\n",
      "bi=300, loss=1.4147493839263916\n",
      "bi=310, loss=1.2424993515014648\n",
      "bi=320, loss=1.039853572845459\n",
      "bi=330, loss=1.123607873916626\n",
      "bi=340, loss=1.2395048141479492\n",
      "bi=350, loss=1.4723703861236572\n",
      "bi=360, loss=0.9506327509880066\n",
      "bi=370, loss=1.3781659603118896\n",
      "bi=380, loss=1.236187219619751\n",
      "bi=390, loss=1.3491723537445068\n",
      "bi=400, loss=1.1544265747070312\n",
      "bi=410, loss=1.2501814365386963\n",
      "bi=420, loss=1.3540434837341309\n",
      "bi=430, loss=1.1909816265106201\n",
      "bi=440, loss=1.3588385581970215\n",
      "bi=450, loss=1.1868562698364258\n",
      "bi=460, loss=1.3238908052444458\n",
      "bi=470, loss=1.2585744857788086\n",
      "bi=480, loss=1.15205717086792\n",
      "bi=490, loss=1.0903851985931396\n",
      "bi=500, loss=0.8737576007843018\n",
      "bi=510, loss=1.311183214187622\n",
      "bi=520, loss=1.1259937286376953\n",
      "bi=530, loss=1.4087145328521729\n",
      "bi=540, loss=1.394615888595581\n",
      "bi=550, loss=1.228853464126587\n",
      "bi=560, loss=1.0808106660842896\n",
      "bi=570, loss=1.077228307723999\n",
      "bi=580, loss=1.4055616855621338\n",
      "bi=590, loss=1.2371851205825806\n",
      "bi=600, loss=1.261908769607544\n",
      "bi=610, loss=1.2365648746490479\n",
      "bi=620, loss=1.3502196073532104\n",
      "bi=630, loss=1.2989346981048584\n",
      "bi=640, loss=1.0612969398498535\n",
      "bi=650, loss=1.3461464643478394\n",
      "bi=660, loss=1.3293052911758423\n",
      "bi=670, loss=1.2086199522018433\n",
      "bi=680, loss=1.240043044090271\n",
      "bi=690, loss=1.4954168796539307\n",
      "bi=700, loss=1.3227858543395996\n",
      "bi=710, loss=1.178292155265808\n",
      "bi=720, loss=1.3337241411209106\n",
      "bi=730, loss=1.3454837799072266\n",
      "bi=740, loss=1.1573987007141113\n",
      "bi=750, loss=1.1508346796035767\n",
      "bi=760, loss=1.313934087753296\n",
      "bi=770, loss=1.1044549942016602\n",
      "bi=780, loss=1.3098293542861938\n",
      "bi=790, loss=1.1123369932174683\n",
      "bi=800, loss=1.136425495147705\n",
      "bi=810, loss=1.2171626091003418\n",
      "bi=820, loss=1.183301568031311\n",
      "bi=830, loss=1.1907157897949219\n",
      "bi=840, loss=1.2847880125045776\n",
      "bi=850, loss=1.2419030666351318\n",
      "bi=860, loss=1.144093632698059\n",
      "bi=870, loss=1.5779755115509033\n",
      "bi=880, loss=1.3205695152282715\n",
      "bi=890, loss=1.074231743812561\n",
      "bi=900, loss=1.2525945901870728\n",
      "bi=910, loss=1.1971561908721924\n",
      "bi=920, loss=1.2222704887390137\n",
      "bi=930, loss=1.1177785396575928\n",
      "bi=940, loss=1.2567248344421387\n",
      "bi=950, loss=1.2178468704223633\n",
      "bi=960, loss=1.1140748262405396\n",
      "bi=970, loss=1.3127996921539307\n",
      "bi=980, loss=1.3878583908081055\n",
      "bi=990, loss=1.048769474029541\n",
      "SCORE = 0.5435235933386867\n",
      "\n",
      "\n",
      "#########################\n",
      "FOLD: 3\n",
      "#########################\n",
      "num_train_steps = 2000\n",
      "bi=0, loss=1.2968730926513672\n",
      "bi=10, loss=1.170231580734253\n",
      "bi=20, loss=1.0098659992218018\n",
      "bi=30, loss=1.1746954917907715\n",
      "bi=40, loss=1.2762622833251953\n",
      "bi=50, loss=1.255172610282898\n",
      "bi=60, loss=1.3673326969146729\n",
      "bi=70, loss=1.2098169326782227\n",
      "bi=80, loss=1.2725071907043457\n",
      "bi=90, loss=1.4491301774978638\n",
      "bi=100, loss=1.3014867305755615\n",
      "bi=110, loss=1.3621989488601685\n",
      "bi=120, loss=1.3377864360809326\n",
      "bi=130, loss=1.5036861896514893\n",
      "bi=140, loss=1.300389289855957\n",
      "bi=150, loss=1.3929510116577148\n",
      "bi=160, loss=1.2605981826782227\n",
      "bi=170, loss=1.230421781539917\n",
      "bi=180, loss=1.4582878351211548\n",
      "bi=190, loss=1.0965304374694824\n",
      "bi=200, loss=1.4009644985198975\n",
      "bi=210, loss=1.3498526811599731\n",
      "bi=220, loss=1.3369786739349365\n",
      "bi=230, loss=1.0740771293640137\n",
      "bi=240, loss=1.2430155277252197\n",
      "bi=250, loss=1.2667791843414307\n",
      "bi=260, loss=1.5426435470581055\n",
      "bi=270, loss=1.2973301410675049\n",
      "bi=280, loss=1.1099178791046143\n",
      "bi=290, loss=1.135928988456726\n",
      "bi=300, loss=1.4767026901245117\n",
      "bi=310, loss=1.2023406028747559\n",
      "bi=320, loss=1.2477720975875854\n",
      "bi=330, loss=1.2551084756851196\n",
      "bi=340, loss=1.261115550994873\n",
      "bi=350, loss=1.2826926708221436\n",
      "bi=360, loss=1.1170392036437988\n",
      "bi=370, loss=1.171379566192627\n",
      "bi=380, loss=1.2398192882537842\n",
      "bi=390, loss=1.207635760307312\n",
      "bi=400, loss=1.2947251796722412\n",
      "bi=410, loss=1.234825849533081\n",
      "bi=420, loss=1.3993914127349854\n",
      "bi=430, loss=1.1484644412994385\n",
      "bi=440, loss=1.3287301063537598\n",
      "bi=450, loss=1.1716904640197754\n",
      "bi=460, loss=1.1969044208526611\n",
      "bi=470, loss=1.17472243309021\n",
      "bi=480, loss=1.1517322063446045\n",
      "bi=490, loss=1.2004191875457764\n",
      "bi=500, loss=1.3595175743103027\n",
      "bi=510, loss=1.4146687984466553\n",
      "bi=520, loss=1.2922652959823608\n",
      "bi=530, loss=1.2448005676269531\n",
      "bi=540, loss=1.2518196105957031\n",
      "bi=550, loss=1.222417950630188\n",
      "bi=560, loss=1.135965347290039\n",
      "bi=570, loss=1.3014287948608398\n",
      "bi=580, loss=1.2313177585601807\n",
      "bi=590, loss=1.4612631797790527\n",
      "bi=600, loss=1.2288721799850464\n",
      "bi=610, loss=1.114636778831482\n",
      "bi=620, loss=1.3777421712875366\n",
      "bi=630, loss=1.1465036869049072\n",
      "bi=640, loss=1.2180323600769043\n",
      "bi=650, loss=1.3426114320755005\n",
      "bi=660, loss=1.1170662641525269\n",
      "bi=670, loss=1.2425940036773682\n",
      "bi=680, loss=1.153993844985962\n",
      "bi=690, loss=1.3485033512115479\n",
      "bi=700, loss=1.092184066772461\n",
      "bi=710, loss=1.0891170501708984\n",
      "bi=720, loss=1.084791898727417\n",
      "bi=730, loss=1.5575146675109863\n",
      "bi=740, loss=1.1598165035247803\n",
      "bi=750, loss=1.1798465251922607\n",
      "bi=760, loss=1.127229928970337\n",
      "bi=770, loss=1.237196922302246\n",
      "bi=780, loss=0.936567485332489\n",
      "bi=790, loss=1.4194906949996948\n",
      "bi=800, loss=1.257455587387085\n",
      "bi=810, loss=1.606482982635498\n",
      "bi=820, loss=1.0553226470947266\n",
      "bi=830, loss=1.174717664718628\n",
      "bi=840, loss=0.9802123308181763\n",
      "bi=850, loss=0.9495705366134644\n",
      "bi=860, loss=1.2100236415863037\n",
      "bi=870, loss=1.4076975584030151\n",
      "bi=880, loss=1.3811815977096558\n",
      "bi=890, loss=1.1160675287246704\n",
      "bi=900, loss=1.1537959575653076\n",
      "bi=910, loss=0.9942766427993774\n",
      "bi=920, loss=1.3753480911254883\n",
      "bi=930, loss=1.3493049144744873\n",
      "bi=940, loss=1.1384673118591309\n",
      "bi=950, loss=1.3725574016571045\n",
      "bi=960, loss=1.1145524978637695\n",
      "bi=970, loss=1.170093297958374\n",
      "bi=980, loss=1.2374589443206787\n",
      "bi=990, loss=1.2313907146453857\n",
      "SCORE = 0.5401155431594221\n",
      "bi=0, loss=1.2993921041488647\n",
      "bi=10, loss=1.178281307220459\n",
      "bi=20, loss=0.9337540864944458\n",
      "bi=30, loss=1.1266505718231201\n",
      "bi=40, loss=1.130841612815857\n",
      "bi=50, loss=1.180420160293579\n",
      "bi=60, loss=1.2215144634246826\n",
      "bi=70, loss=1.0596098899841309\n",
      "bi=80, loss=1.2248297929763794\n",
      "bi=90, loss=1.4544463157653809\n",
      "bi=100, loss=1.2968230247497559\n",
      "bi=110, loss=1.1688774824142456\n",
      "bi=120, loss=1.1676794290542603\n",
      "bi=130, loss=1.380893349647522\n",
      "bi=140, loss=1.2698564529418945\n",
      "bi=150, loss=1.2586088180541992\n",
      "bi=160, loss=1.1533632278442383\n",
      "bi=170, loss=1.2533376216888428\n",
      "bi=180, loss=1.5064603090286255\n",
      "bi=190, loss=1.1542353630065918\n",
      "bi=200, loss=1.3107597827911377\n",
      "bi=210, loss=1.1777358055114746\n",
      "bi=220, loss=1.3723658323287964\n",
      "bi=230, loss=1.0482966899871826\n",
      "bi=240, loss=1.1439619064331055\n",
      "bi=250, loss=1.129492998123169\n",
      "bi=260, loss=1.249058723449707\n",
      "bi=270, loss=1.3450520038604736\n",
      "bi=280, loss=1.3185756206512451\n",
      "bi=290, loss=1.1549416780471802\n",
      "bi=300, loss=1.2553470134735107\n",
      "bi=310, loss=1.183624267578125\n",
      "bi=320, loss=1.2395954132080078\n",
      "bi=330, loss=1.1002707481384277\n",
      "bi=340, loss=1.061988353729248\n",
      "bi=350, loss=1.250228762626648\n",
      "bi=360, loss=1.0381426811218262\n",
      "bi=370, loss=1.0842996835708618\n",
      "bi=380, loss=1.1949546337127686\n",
      "bi=390, loss=1.2853970527648926\n",
      "bi=400, loss=1.1701709032058716\n",
      "bi=410, loss=1.1318714618682861\n",
      "bi=420, loss=1.2634029388427734\n",
      "bi=430, loss=1.0901923179626465\n",
      "bi=440, loss=1.2888553142547607\n",
      "bi=450, loss=1.0319781303405762\n",
      "bi=460, loss=1.0860753059387207\n",
      "bi=470, loss=1.4196869134902954\n",
      "bi=480, loss=1.264616847038269\n",
      "bi=490, loss=1.0568146705627441\n",
      "bi=500, loss=1.3414068222045898\n",
      "bi=510, loss=1.3510451316833496\n",
      "bi=520, loss=1.344238042831421\n",
      "bi=530, loss=1.1953051090240479\n",
      "bi=540, loss=1.3017258644104004\n",
      "bi=550, loss=1.1674106121063232\n",
      "bi=560, loss=1.2339816093444824\n",
      "bi=570, loss=1.0191659927368164\n",
      "bi=580, loss=1.2339437007904053\n",
      "bi=590, loss=1.46343195438385\n",
      "bi=600, loss=1.3115370273590088\n",
      "bi=610, loss=1.2639501094818115\n",
      "bi=620, loss=1.2988814115524292\n",
      "bi=630, loss=1.050166130065918\n",
      "bi=640, loss=1.2291709184646606\n",
      "bi=650, loss=1.4872510433197021\n",
      "bi=660, loss=0.9987584352493286\n",
      "bi=670, loss=1.1649816036224365\n",
      "bi=680, loss=1.1251052618026733\n",
      "bi=690, loss=1.295585036277771\n",
      "bi=700, loss=0.9515622854232788\n",
      "bi=710, loss=0.9547234773635864\n",
      "bi=720, loss=0.9736733436584473\n",
      "bi=730, loss=1.4211453199386597\n",
      "bi=740, loss=1.027903437614441\n",
      "bi=750, loss=1.0821480751037598\n",
      "bi=760, loss=1.1509679555892944\n",
      "bi=770, loss=1.1701115369796753\n",
      "bi=780, loss=0.84637451171875\n",
      "bi=790, loss=1.4405572414398193\n",
      "bi=800, loss=1.0246028900146484\n",
      "bi=810, loss=1.485220193862915\n",
      "bi=820, loss=1.0485866069793701\n",
      "bi=830, loss=1.0727906227111816\n",
      "bi=840, loss=0.9288936853408813\n",
      "bi=850, loss=1.0044890642166138\n",
      "bi=860, loss=1.178579568862915\n",
      "bi=870, loss=1.4943652153015137\n",
      "bi=880, loss=1.357534408569336\n",
      "bi=890, loss=1.0326292514801025\n",
      "bi=900, loss=1.0746114253997803\n",
      "bi=910, loss=1.0251812934875488\n",
      "bi=920, loss=1.3311328887939453\n",
      "bi=930, loss=1.0167975425720215\n",
      "bi=940, loss=1.0818711519241333\n",
      "bi=950, loss=1.2296173572540283\n",
      "bi=960, loss=1.120849370956421\n",
      "bi=970, loss=1.2288603782653809\n",
      "bi=980, loss=1.2013297080993652\n",
      "bi=990, loss=1.2199803590774536\n",
      "SCORE = 0.5474099863469027\n",
      "\n",
      "\n",
      "#########################\n",
      "FOLD: 4\n",
      "#########################\n",
      "num_train_steps = 2000\n",
      "bi=0, loss=1.2563776969909668\n",
      "bi=10, loss=1.2921559810638428\n",
      "bi=20, loss=1.1469981670379639\n",
      "bi=30, loss=1.5526444911956787\n",
      "bi=40, loss=1.299687385559082\n",
      "bi=50, loss=1.3262667655944824\n",
      "bi=60, loss=1.3782322406768799\n",
      "bi=70, loss=1.2032394409179688\n",
      "bi=80, loss=1.327483892440796\n",
      "bi=90, loss=1.448496699333191\n",
      "bi=100, loss=1.3014085292816162\n",
      "bi=110, loss=1.2918782234191895\n",
      "bi=120, loss=1.3883966207504272\n",
      "bi=130, loss=1.1631968021392822\n",
      "bi=140, loss=1.1087582111358643\n",
      "bi=150, loss=1.1093974113464355\n",
      "bi=160, loss=1.2260569334030151\n",
      "bi=170, loss=1.3174281120300293\n",
      "bi=180, loss=1.3656554222106934\n",
      "bi=190, loss=1.134920597076416\n",
      "bi=200, loss=1.1723811626434326\n",
      "bi=210, loss=1.2177300453186035\n",
      "bi=220, loss=1.5448085069656372\n",
      "bi=230, loss=1.0785688161849976\n",
      "bi=240, loss=1.274096965789795\n",
      "bi=250, loss=1.1142926216125488\n",
      "bi=260, loss=1.322883129119873\n",
      "bi=270, loss=1.2014857530593872\n",
      "bi=280, loss=1.162243366241455\n",
      "bi=290, loss=1.2264587879180908\n",
      "bi=300, loss=1.3284857273101807\n",
      "bi=310, loss=1.2671027183532715\n",
      "bi=320, loss=1.0494472980499268\n",
      "bi=330, loss=1.2296321392059326\n",
      "bi=340, loss=1.043540596961975\n",
      "bi=350, loss=1.4377309083938599\n",
      "bi=360, loss=1.315386414527893\n",
      "bi=370, loss=1.345657467842102\n",
      "bi=380, loss=1.1400281190872192\n",
      "bi=390, loss=0.9530029892921448\n",
      "bi=400, loss=1.3612334728240967\n",
      "bi=410, loss=1.318030595779419\n",
      "bi=420, loss=1.1387887001037598\n",
      "bi=430, loss=1.5261536836624146\n",
      "bi=440, loss=1.0957247018814087\n",
      "bi=450, loss=1.2216403484344482\n",
      "bi=460, loss=1.3622123003005981\n",
      "bi=470, loss=1.3777117729187012\n",
      "bi=480, loss=1.329110860824585\n",
      "bi=490, loss=1.076172113418579\n",
      "bi=500, loss=1.0634562969207764\n",
      "bi=510, loss=1.0255576372146606\n",
      "bi=520, loss=1.2523539066314697\n",
      "bi=530, loss=1.1915756464004517\n",
      "bi=540, loss=1.0107934474945068\n",
      "bi=550, loss=1.5219721794128418\n",
      "bi=560, loss=1.1758122444152832\n",
      "bi=570, loss=1.3948533535003662\n",
      "bi=580, loss=1.302760124206543\n",
      "bi=590, loss=1.044945240020752\n",
      "bi=600, loss=1.2302035093307495\n",
      "bi=610, loss=1.1876428127288818\n",
      "bi=620, loss=1.2402081489562988\n",
      "bi=630, loss=1.2770519256591797\n",
      "bi=640, loss=1.0729973316192627\n",
      "bi=650, loss=1.5474796295166016\n",
      "bi=660, loss=1.245735764503479\n",
      "bi=670, loss=1.2687170505523682\n",
      "bi=680, loss=1.3716591596603394\n",
      "bi=690, loss=1.1462504863739014\n",
      "bi=700, loss=1.3097186088562012\n",
      "bi=710, loss=0.9901270866394043\n",
      "bi=720, loss=1.4951517581939697\n",
      "bi=730, loss=1.265272617340088\n",
      "bi=740, loss=1.1341633796691895\n",
      "bi=750, loss=0.9334760904312134\n",
      "bi=760, loss=1.220618486404419\n",
      "bi=770, loss=1.3037939071655273\n",
      "bi=780, loss=1.3217575550079346\n",
      "bi=790, loss=1.2677443027496338\n",
      "bi=800, loss=1.058171272277832\n",
      "bi=810, loss=1.3944859504699707\n",
      "bi=820, loss=1.312396764755249\n",
      "bi=830, loss=1.2325758934020996\n",
      "bi=840, loss=1.2317663431167603\n",
      "bi=850, loss=1.2795608043670654\n",
      "bi=860, loss=1.252041220664978\n",
      "bi=870, loss=1.2435036897659302\n",
      "bi=880, loss=1.154303789138794\n",
      "bi=890, loss=1.1003338098526\n",
      "bi=900, loss=1.2131500244140625\n",
      "bi=910, loss=1.226210117340088\n",
      "bi=920, loss=1.459120273590088\n",
      "bi=930, loss=1.4624462127685547\n",
      "bi=940, loss=1.0945687294006348\n",
      "bi=950, loss=1.1479533910751343\n",
      "bi=960, loss=1.1822726726531982\n",
      "bi=970, loss=0.9467188715934753\n",
      "bi=980, loss=1.2291837930679321\n",
      "bi=990, loss=1.3029565811157227\n",
      "SCORE = 0.5504240400896122\n",
      "bi=0, loss=1.2662838697433472\n",
      "bi=10, loss=1.1506264209747314\n",
      "bi=20, loss=1.1832892894744873\n",
      "bi=30, loss=1.7537853717803955\n",
      "bi=40, loss=1.16905677318573\n",
      "bi=50, loss=1.4069024324417114\n",
      "bi=60, loss=1.3649359941482544\n",
      "bi=70, loss=1.2218300104141235\n",
      "bi=80, loss=1.1171586513519287\n",
      "bi=90, loss=1.3659929037094116\n",
      "bi=100, loss=1.2902097702026367\n",
      "bi=110, loss=1.304295539855957\n",
      "bi=120, loss=1.209424376487732\n",
      "bi=130, loss=1.0249284505844116\n",
      "bi=140, loss=1.086377501487732\n",
      "bi=150, loss=0.9504099488258362\n",
      "bi=160, loss=1.0002189874649048\n",
      "bi=170, loss=1.3120659589767456\n",
      "bi=180, loss=1.4990923404693604\n",
      "bi=190, loss=0.9774831533432007\n",
      "bi=200, loss=1.2052161693572998\n",
      "bi=210, loss=1.0372467041015625\n",
      "bi=220, loss=1.4988560676574707\n",
      "bi=230, loss=1.0221298933029175\n",
      "bi=240, loss=1.2524281740188599\n",
      "bi=250, loss=1.179250955581665\n",
      "bi=260, loss=1.284885287284851\n",
      "bi=270, loss=1.235790729522705\n",
      "bi=280, loss=1.0877413749694824\n",
      "bi=290, loss=1.308377981185913\n",
      "bi=300, loss=1.280748724937439\n",
      "bi=310, loss=1.176677942276001\n",
      "bi=320, loss=1.0292247533798218\n",
      "bi=330, loss=1.218290090560913\n",
      "bi=340, loss=1.050167441368103\n",
      "bi=350, loss=1.2178890705108643\n",
      "bi=360, loss=1.3415201902389526\n",
      "bi=370, loss=1.3351311683654785\n",
      "bi=380, loss=1.0466270446777344\n",
      "bi=390, loss=1.0380877256393433\n",
      "bi=400, loss=1.369322419166565\n",
      "bi=410, loss=1.3049964904785156\n",
      "bi=420, loss=1.0763354301452637\n",
      "bi=430, loss=1.399857759475708\n",
      "bi=440, loss=1.009017825126648\n",
      "bi=450, loss=1.3782415390014648\n",
      "bi=460, loss=1.3540595769882202\n",
      "bi=470, loss=1.308971643447876\n",
      "bi=480, loss=1.1263148784637451\n",
      "bi=490, loss=1.1662633419036865\n",
      "bi=500, loss=1.0239312648773193\n",
      "bi=510, loss=1.1126351356506348\n",
      "bi=520, loss=1.4057953357696533\n",
      "bi=530, loss=1.1486819982528687\n",
      "bi=540, loss=0.912467360496521\n",
      "bi=550, loss=1.2072765827178955\n",
      "bi=560, loss=1.1415212154388428\n",
      "bi=570, loss=1.336094617843628\n",
      "bi=580, loss=1.288785457611084\n",
      "bi=590, loss=1.0185978412628174\n",
      "bi=600, loss=1.3160724639892578\n",
      "bi=610, loss=1.139965295791626\n",
      "bi=620, loss=1.3340818881988525\n",
      "bi=630, loss=1.3258376121520996\n",
      "bi=640, loss=0.9800212383270264\n",
      "bi=650, loss=1.5561251640319824\n",
      "bi=660, loss=1.1038799285888672\n",
      "bi=670, loss=1.1397228240966797\n",
      "bi=680, loss=1.3011547327041626\n",
      "bi=690, loss=1.1747026443481445\n",
      "bi=700, loss=1.3638081550598145\n",
      "bi=710, loss=0.7492961287498474\n",
      "bi=720, loss=1.3266607522964478\n",
      "bi=730, loss=1.214914321899414\n",
      "bi=740, loss=1.034443974494934\n",
      "bi=750, loss=0.8058669567108154\n",
      "bi=760, loss=1.2521202564239502\n",
      "bi=770, loss=1.285150408744812\n",
      "bi=780, loss=1.3601187467575073\n",
      "bi=790, loss=1.1587412357330322\n",
      "bi=800, loss=0.8914669752120972\n",
      "bi=810, loss=1.5928953886032104\n",
      "bi=820, loss=1.192523717880249\n",
      "bi=830, loss=1.2996159791946411\n",
      "bi=840, loss=1.0722968578338623\n",
      "bi=850, loss=1.323838472366333\n",
      "bi=860, loss=1.1556063890457153\n",
      "bi=870, loss=1.2446037530899048\n",
      "bi=880, loss=1.2127792835235596\n",
      "bi=890, loss=1.04718017578125\n",
      "bi=900, loss=1.1756398677825928\n",
      "bi=910, loss=1.0537667274475098\n",
      "bi=920, loss=1.3485981225967407\n",
      "bi=930, loss=1.17094087600708\n",
      "bi=940, loss=1.0126943588256836\n",
      "bi=950, loss=1.1109163761138916\n",
      "bi=960, loss=1.2545812129974365\n",
      "bi=970, loss=0.8122097253799438\n",
      "bi=980, loss=1.1770730018615723\n",
      "bi=990, loss=1.2483457326889038\n",
      "SCORE = 0.5544095970996998\n",
      "\n",
      "\n",
      "#########################\n",
      "FOLD: 5\n",
      "#########################\n",
      "num_train_steps = 2000\n",
      "bi=0, loss=1.0317342281341553\n",
      "bi=10, loss=1.2487486600875854\n",
      "bi=20, loss=1.3604426383972168\n",
      "bi=30, loss=1.2890535593032837\n",
      "bi=40, loss=1.4464035034179688\n",
      "bi=50, loss=1.0881826877593994\n",
      "bi=60, loss=0.9848887324333191\n",
      "bi=70, loss=1.0209400653839111\n",
      "bi=80, loss=1.3192634582519531\n",
      "bi=90, loss=1.3323273658752441\n",
      "bi=100, loss=1.2194331884384155\n",
      "bi=110, loss=1.2432301044464111\n",
      "bi=120, loss=1.1416679620742798\n",
      "bi=130, loss=1.4645624160766602\n",
      "bi=140, loss=1.2702484130859375\n",
      "bi=150, loss=0.921497106552124\n",
      "bi=160, loss=1.053309440612793\n",
      "bi=170, loss=1.4043744802474976\n",
      "bi=180, loss=0.9561309814453125\n",
      "bi=190, loss=1.2274701595306396\n",
      "bi=200, loss=1.0955040454864502\n",
      "bi=210, loss=1.2188020944595337\n",
      "bi=220, loss=1.3398914337158203\n",
      "bi=230, loss=1.0970544815063477\n",
      "bi=240, loss=1.3094426393508911\n",
      "bi=250, loss=1.2103523015975952\n",
      "bi=260, loss=1.1926778554916382\n",
      "bi=270, loss=1.4312129020690918\n",
      "bi=280, loss=1.2821458578109741\n",
      "bi=290, loss=1.2073595523834229\n",
      "bi=300, loss=1.2027556896209717\n",
      "bi=310, loss=1.385081171989441\n",
      "bi=320, loss=1.1937472820281982\n",
      "bi=330, loss=1.1063345670700073\n",
      "bi=340, loss=1.146664023399353\n",
      "bi=350, loss=1.159912109375\n",
      "bi=360, loss=1.3210411071777344\n",
      "bi=370, loss=1.1774749755859375\n",
      "bi=380, loss=1.2888216972351074\n",
      "bi=390, loss=1.145189881324768\n",
      "bi=400, loss=1.350748062133789\n",
      "bi=410, loss=1.1803808212280273\n",
      "bi=420, loss=1.699939489364624\n",
      "bi=430, loss=1.0607922077178955\n",
      "bi=440, loss=1.1942956447601318\n",
      "bi=450, loss=1.2652788162231445\n",
      "bi=460, loss=1.450124740600586\n",
      "bi=470, loss=1.162438154220581\n",
      "bi=480, loss=1.2387073040008545\n",
      "bi=490, loss=1.143528699874878\n",
      "bi=500, loss=1.4231090545654297\n",
      "bi=510, loss=1.3377184867858887\n",
      "bi=520, loss=1.247231364250183\n",
      "bi=530, loss=1.240775465965271\n",
      "bi=540, loss=1.295942783355713\n",
      "bi=550, loss=1.322981834411621\n",
      "bi=560, loss=1.277672290802002\n",
      "bi=570, loss=1.065319299697876\n",
      "bi=580, loss=1.1642308235168457\n",
      "bi=590, loss=1.2020841836929321\n",
      "bi=600, loss=0.9069800972938538\n",
      "bi=610, loss=1.2016501426696777\n",
      "bi=620, loss=1.1485650539398193\n",
      "bi=630, loss=1.3277392387390137\n",
      "bi=640, loss=1.1944713592529297\n",
      "bi=650, loss=1.1882424354553223\n",
      "bi=660, loss=1.1961193084716797\n",
      "bi=670, loss=1.2655043601989746\n",
      "bi=680, loss=1.0920861959457397\n",
      "bi=690, loss=1.2092537879943848\n",
      "bi=700, loss=1.077063798904419\n",
      "bi=710, loss=1.245234727859497\n",
      "bi=720, loss=1.0808956623077393\n",
      "bi=730, loss=1.645051121711731\n",
      "bi=740, loss=1.2157344818115234\n",
      "bi=750, loss=1.6703696250915527\n",
      "bi=760, loss=1.150339126586914\n",
      "bi=770, loss=1.2402739524841309\n",
      "bi=780, loss=1.106366515159607\n",
      "bi=790, loss=0.9344887733459473\n",
      "bi=800, loss=1.0627679824829102\n",
      "bi=810, loss=1.604657769203186\n",
      "bi=820, loss=1.4567676782608032\n",
      "bi=830, loss=1.400713324546814\n",
      "bi=840, loss=0.9985402822494507\n",
      "bi=850, loss=1.168795108795166\n",
      "bi=860, loss=1.1263079643249512\n",
      "bi=870, loss=1.2107024192810059\n",
      "bi=880, loss=1.2556325197219849\n",
      "bi=890, loss=1.375455617904663\n",
      "bi=900, loss=0.9668073058128357\n",
      "bi=910, loss=1.1626790761947632\n",
      "bi=920, loss=1.1239384412765503\n",
      "bi=930, loss=1.0177080631256104\n",
      "bi=940, loss=1.1210682392120361\n",
      "bi=950, loss=1.100771188735962\n",
      "bi=960, loss=1.2079304456710815\n",
      "bi=970, loss=1.1461825370788574\n",
      "bi=980, loss=1.4737801551818848\n",
      "bi=990, loss=1.2659356594085693\n",
      "SCORE = 0.5404388709969421\n",
      "bi=0, loss=1.0809762477874756\n",
      "bi=10, loss=1.2716178894042969\n",
      "bi=20, loss=1.1286835670471191\n",
      "bi=30, loss=1.3417713642120361\n",
      "bi=40, loss=1.4328762292861938\n",
      "bi=50, loss=1.0608116388320923\n",
      "bi=60, loss=1.0691494941711426\n",
      "bi=70, loss=0.9992454051971436\n",
      "bi=80, loss=1.3364078998565674\n",
      "bi=90, loss=1.3355680704116821\n",
      "bi=100, loss=1.2132850885391235\n",
      "bi=110, loss=1.2013919353485107\n",
      "bi=120, loss=1.2255473136901855\n",
      "bi=130, loss=1.0415396690368652\n",
      "bi=140, loss=1.2489615678787231\n",
      "bi=150, loss=0.8549706935882568\n",
      "bi=160, loss=1.0408517122268677\n",
      "bi=170, loss=1.360344648361206\n",
      "bi=180, loss=0.928886353969574\n",
      "bi=190, loss=1.3013120889663696\n",
      "bi=200, loss=1.0969189405441284\n",
      "bi=210, loss=1.3294587135314941\n",
      "bi=220, loss=1.4989930391311646\n",
      "bi=230, loss=1.085448980331421\n",
      "bi=240, loss=1.191291332244873\n",
      "bi=250, loss=1.0965042114257812\n",
      "bi=260, loss=1.2249798774719238\n",
      "bi=270, loss=1.3635883331298828\n",
      "bi=280, loss=1.1135278940200806\n",
      "bi=290, loss=1.1761343479156494\n",
      "bi=300, loss=1.2476661205291748\n",
      "bi=310, loss=1.2578635215759277\n",
      "bi=320, loss=1.1066447496414185\n",
      "bi=330, loss=1.1123254299163818\n",
      "bi=340, loss=1.1439080238342285\n",
      "bi=350, loss=1.3717353343963623\n",
      "bi=360, loss=1.1890935897827148\n",
      "bi=370, loss=1.1710777282714844\n",
      "bi=380, loss=1.1655609607696533\n",
      "bi=390, loss=1.1956323385238647\n",
      "bi=400, loss=1.5396932363510132\n",
      "bi=410, loss=1.132599949836731\n",
      "bi=420, loss=1.3731238842010498\n",
      "bi=430, loss=0.965836763381958\n",
      "bi=440, loss=0.9522222280502319\n",
      "bi=450, loss=1.0460699796676636\n",
      "bi=460, loss=1.1984549760818481\n",
      "bi=470, loss=1.0885837078094482\n",
      "bi=480, loss=1.3855067491531372\n",
      "bi=490, loss=1.0183179378509521\n",
      "bi=500, loss=1.3466582298278809\n",
      "bi=510, loss=1.2110509872436523\n",
      "bi=520, loss=1.2072844505310059\n",
      "bi=530, loss=1.2031487226486206\n",
      "bi=540, loss=1.2965679168701172\n",
      "bi=550, loss=1.208115816116333\n",
      "bi=560, loss=1.1562340259552002\n",
      "bi=570, loss=0.9998807907104492\n",
      "bi=580, loss=1.1240465641021729\n",
      "bi=590, loss=1.077295184135437\n",
      "bi=600, loss=0.8195451498031616\n",
      "bi=610, loss=1.1979902982711792\n",
      "bi=620, loss=1.0917048454284668\n",
      "bi=630, loss=1.288114309310913\n",
      "bi=640, loss=1.0723942518234253\n",
      "bi=650, loss=1.1699050664901733\n",
      "bi=660, loss=1.277675986289978\n",
      "bi=670, loss=1.2825416326522827\n",
      "bi=680, loss=1.0862209796905518\n",
      "bi=690, loss=1.161844253540039\n",
      "bi=700, loss=0.9773446917533875\n",
      "bi=710, loss=1.0359230041503906\n",
      "bi=720, loss=0.9285675883293152\n",
      "bi=730, loss=1.4871387481689453\n",
      "bi=740, loss=1.139887809753418\n",
      "bi=750, loss=1.6985092163085938\n",
      "bi=760, loss=1.0671262741088867\n",
      "bi=770, loss=1.4682772159576416\n",
      "bi=780, loss=1.1727931499481201\n",
      "bi=790, loss=1.0116503238677979\n",
      "bi=800, loss=0.9366345405578613\n",
      "bi=810, loss=1.2709136009216309\n",
      "bi=820, loss=1.2565815448760986\n",
      "bi=830, loss=1.2552908658981323\n",
      "bi=840, loss=0.9482444524765015\n",
      "bi=850, loss=1.1622164249420166\n",
      "bi=860, loss=0.8321661949157715\n",
      "bi=870, loss=1.1646831035614014\n",
      "bi=880, loss=1.281167984008789\n",
      "bi=890, loss=1.2710016965866089\n",
      "bi=900, loss=1.0143623352050781\n",
      "bi=910, loss=1.2172473669052124\n",
      "bi=920, loss=1.2741717100143433\n",
      "bi=930, loss=1.1343016624450684\n",
      "bi=940, loss=1.0493948459625244\n",
      "bi=950, loss=1.0703881978988647\n",
      "bi=960, loss=1.232748031616211\n",
      "bi=970, loss=0.953439474105835\n",
      "bi=980, loss=1.4623956680297852\n",
      "bi=990, loss=1.405208706855774\n",
      "SCORE = 0.5525898806745508\n"
     ]
    }
   ],
   "source": [
    "_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('./model.bin')\n",
    "# mx.load_state_dict(checkpoint);\n",
    "# mx.eval();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "003a1656df1c46fd8b2969098f2b1c1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1b5aec44d3644d4fbd05336eafdfc811",
       "max": 36804509.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b923e721de14ef5942eee97785f7319",
       "value": 36804509.0
      }
     },
     "1b5aec44d3644d4fbd05336eafdfc811": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b923e721de14ef5942eee97785f7319": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "67a408f1c6994883bc37e6214573c5b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_003a1656df1c46fd8b2969098f2b1c1a",
        "IPY_MODEL_87d271df10814cf38d370e368a3adc53"
       ],
       "layout": "IPY_MODEL_6e54a1b48f3a4e71906077caf9f1394e"
      }
     },
     "6e54a1b48f3a4e71906077caf9f1394e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "87d271df10814cf38d370e368a3adc53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d8173b5fed584ea8a82f111032a9ba01",
       "placeholder": "​",
       "style": "IPY_MODEL_cb68e95df16749a4878643805b952f60",
       "value": " 35.1M/35.1M [00:09&lt;00:00, 3.94MB/s]"
      }
     },
     "cb68e95df16749a4878643805b952f60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d8173b5fed584ea8a82f111032a9ba01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
